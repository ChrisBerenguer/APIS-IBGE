{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224fe8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0fe222",
   "metadata": {},
   "source": [
    "Função simulada para obter a temperatura de algumas cidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bacd926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A temperatura em São Paulo é de 32°C e em Porto Alegre é de 25°C.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (Aqui não há consulta a uma API real, apenas retorna valores fixos para exemplos)\n",
    "def obter_temperatura_atual(local, unidade=\"celsius\"):\n",
    "    if \"são paulo\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {\"local\": \"São Paulo\", \"temperatura\": \"32\", \"unidade\": unidade}\n",
    "            )\n",
    "    elif \"porto alegre\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {\"local\": \"Porto Alegre\", \"temperatura\": \"25\", \"unidade\": unidade}\n",
    "            )\n",
    "    elif \"rio de janeiro\" in local.lower():\n",
    "        return json.dumps(\n",
    "            {\"local\": \"Rio de Janeiro\", \"temperatura\": \"35\", \"unidade\": unidade}\n",
    "            )\n",
    "    else:\n",
    "        return json.dumps(\n",
    "            {\"local\": local, \"temperatura\": \"unknown\"}\n",
    "            )\n",
    "\n",
    "# Define a ferramenta (function) que será disponibilizada para o modelo\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"obter_temperatura_atual\",\n",
    "            \"description\": \"Obtém a temperatura atual em uma dada cidade\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"local\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"O nome da cidade. Ex: São Paulo\",\n",
    "                    },\n",
    "                    \"unidade\": {\n",
    "                        \"type\": \"string\", \n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"local\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    ]\n",
    "\n",
    "# Dicionário que mapeia o nome da função para a função real em Python\n",
    "funcoes_disponiveis = {\n",
    "        \"obter_temperatura_atual\": obter_temperatura_atual,\n",
    "    }\n",
    "\n",
    "# Mensagem inicial do usuário para o chatbot\n",
    "mensagens = [\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"Qual é a temperatura em São Paulo e Porto Alegre?\"}\n",
    "    ]\n",
    "\n",
    "# Faz a primeira chamada para o modelo, informando as ferramentas disponíveis\n",
    "resposta = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=mensagens,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "# Extrai a mensagem de resposta do modelo\n",
    "mensagem_resp = resposta.choices[0].message\n",
    "tool_calls = mensagem_resp.tool_calls\n",
    "\n",
    "# Se o modelo solicitou o uso de alguma função (tool_call), executa as funções\n",
    "if tool_calls:\n",
    "    # Adiciona a resposta do modelo ao histórico de mensagens\n",
    "    mensagens.append(mensagem_resp)\n",
    "    for tool_call in tool_calls:\n",
    "        # Nome da função a ser chamada\n",
    "        function_name = tool_call.function.name\n",
    "        # Função Python correspondente\n",
    "        function_to_call = funcoes_disponiveis[function_name]\n",
    "        # Argumentos da função (convertidos de string JSON para dicionário)\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        # Executa a função e obtém a resposta\n",
    "        function_response = function_to_call(\n",
    "            local=function_args.get(\"local\"),\n",
    "            unidade=function_args.get(\"unidade\"),\n",
    "        )\n",
    "        # Adiciona a resposta da função ao histórico de mensagens\n",
    "        mensagens.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "    # Faz uma segunda chamada ao modelo, agora com as respostas das funções\n",
    "    segunda_resposta = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=mensagens,\n",
    "    )\n",
    "\n",
    "# Extrai a resposta final do modelo e imprime\n",
    "mensagem_resp = segunda_resposta.choices[0].message\n",
    "# Exibe a resposta final ao usuário\n",
    "print(mensagem_resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a7bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
